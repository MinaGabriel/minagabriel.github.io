<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CISC 435 (ML)</title>
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css">
</head>

<body>
    <header class="bg-primary text-white text-center py-4">
        <h2>CISC 435 Machine Learning Fundamentals (FALL 2023)</h2>
    </header>

    <main class="container my-5">
        <section class="mb-4">
            <h3>Course Description</h3>
            <p>This course provides a broad introduction to machine learning, statistical pattern recognition, and deep
                learning. Students gain practical knowledge and skills in machine learning algorithms by tackling
                real-world problems through programming projects. The lectures will cover linear models, kernel
                machines, mixture models, neural networks, and deep learning. Offered in the Fall semester, annually.
            </p>
        </section>
       
        

        <section class="mb-4">
            <h3>Pre-requisites</h3>
            <p>Prerequisites: CISC 340 - Introduction to Artificial Intelligence and MATH 250 - Introduction to Linear
                Algebra. Basic understanding of probability, statistics, college-level algebra, and calculus is
                required.</p>
        </section>

        <section class="mb-4">
            <h3>Grading Criteria</h3>
            <ul>
                <li>Assignments (8 in total): 50%</li>
                <ul>
                    <li>Assignment 1: 5%</li>
                    <li>Assignment 2: 5%</li>
                    <li>Assignment 3: 5%</li>
                    <li>Assignment 4: 5%</li>
                    <li>Assignment 5: 5%</li>
                    <li>Assignment 6: 10%</li>
                    <li>Assignment 7: 10%</li>
                    <li>Assignment 8: 5%</li>
                </ul>
                <li>Midterm Exam: 20%</li>
                <li>Final Exam: 10%</li>
                <li>Final Project: 20%</li>
            </ul>
        </section>

        <section class="mb-4">
            <h3>Course Information</h3>
            <ul>
                <li><strong>Lectures:</strong> Tuesday & Thursday 10:00 AM - 11:30 AM</li>
                <li><strong>Lecture Room:</strong> Harrisburg University Main Campus, 326 Market Street Building, 1305
                </li>
                <li><strong>Instructor:</strong> Mina Gabriel (mgabriel [at] harrisburgu [dot] edu)</li>
                <li><strong>Office hours:</strong> Room 1127, Tuesday & Thursday 02:10 PM - 03:10 PM & by appointment
                </li>
            </ul>
        </section>

        <section>
            <h3>Course Schedule (tentative)</h3>
            <p>The following schedule is approximate and subject to change. Additionally, the slides provided prior to
                the day of the class may not be fully updated and are also subject to change.</p>
            <table class="table table-striped">
                <thead>
                    <tr>
                        <th scope="col">Week</th>
                        <th scope="col">Topics</th>
                        <th scope="col">Reading</th>
                        <th scope="col">Slides</th>
                        <th scope="col">Assignment</th>
                        <th scope="col">Due Dates</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <th scope="row">Week 1: Introduction to Machine Learning</th>
                        <td>- Course Introduction</td>
                        <td><a href="cisc-435/readings/math4ml.pdf">Math for Machine Learning</a></td>
                        <td>Slides: <a href="cisc-435/lectures/intro.pdf">Introduction</a></td>
                        <td><a href="cisc-435/assignment/CISC_435_Assignment01.pdf">A01: Math & Programming Review</a>
                        </td>
                        <td></td>
                    </tr>
                    <tr>
                        <th scope="row">Week 2: Bayes Rule</th>
                        <td>
                            - Introduction to Bayesian statistics<br>
                            - Na√Øve Bayes<br>
                            - Gaussian Models
                        </td>
                        <td><a target="_blank"
                                href="https://medium.com/@minagabriel/maximum-likelihood-estimation-mle-theory-and-working-example-b59146da93e">MLE</a><br>
                            <a href="http://ciml.info/dl/v0_99/ciml-v0_99-ch09.pdf">CML Section: 9.1-9.3</a>
                        </td>
                        <td>Slides: <a href="cisc-435/lectures/02-bayesclass.pdf">Bayes Classifiers</a></td>
                        <td><a href="cisc-435/assignment/CISC_435_Assignment02.pdf">A02: Bayes Rule</a></td>
                        <td>A01: 09/07</td>
                    </tr>
                    <tr>
                        <th scope="row">Week 3: Supervised Learning - Regression </th>
                        <td>
                            - Linear regression<br>
                            - Polynomial regression
                        </td>
                        <td><a href="http://ciml.info/dl/v0_99/ciml-v0_99-ch07.pdf">CML Ch 7</a></td>
                        <td>Slides: <a href="cisc-435/lectures/04-linRegress.pdf">Linear regression</a></td>
                        <td></td>
                        <td></td>
                    </tr>
                    <tr>
                        <th scope="row">Week 4: Supervised Learning - Classification </th>
                        <td>
                            - Logistic regression<br>
                            - K-nearest neighbors (KNN)
                        </td>
                        <td><a href="http://ciml.info/dl/v0_99/ciml-v0_99-ch03.pdf">CML Ch 3</a></td>
                        <td>Slides: <a href="cisc-435/lectures/05-linClassify.pdf">Linear classification</a><br>
                            Slides: <a href="cisc-435/lectures/03-knn.pdf">Nearest neighbor methods</a>
                        </td>
                        <td><a href="cisc-435/assignment/CISC_435_Assignment03.pdf">A03: Regression</a></td>
                        <td>A02: 09/21</td>
                    </tr>
                    <tr>
                        <th scope="row">Week 5: Supervised Learning - Decision Trees and Random Forests</th>
                        <td>
                            - Decision trees<br>
                            - Ensemble methods: random forests<br>
                            - Feature importance and interpretation
                        </td>
                        <td><a href="http://ciml.info/dl/v0_99/ciml-v0_99-ch01.pdf">CML Section: 1.1-1.3</a></td>
                        <td>Slides: <a href="cisc-435/lectures/09-dectree.pdf">Decision Trees</a><br>
                            Slides: <a href="cisc-435/lectures/10-ensembles.pdf">Ensembles of Learners</a>
                        </td>
                        <td></td>
                        <td></td>
                    </tr>
                    <tr>
                        <th scope="row">Week 6: Unsupervised Learning - Clustering</th>
                        <td>
                            - K-means clustering<br>
                            - Hierarchical clustering<br>
                            - Evaluation metrics for clustering
                        </td>
                        <td><a href="cisc-435/readings/K-Means.pdf">Andrew Ng: K-means</a></td>
                        <td>Slides: <a href="cisc-435/lectures/21-clustering.pdf">Clustering</a></td>
                        <td><a href="cisc-435/assignment/CISC_435_Assignment04.pdf">A04: Trees & Clustering</a> </td>
                        <td>A03: 10/05</td>
                    </tr>

                    <tr>
                        <th scope="row">Week 7: Unsupervised Learning - Dimensionality Reduction</th>
                        <td>
                            - Principal Component Analysis (PCA)<br>
                            - Singular Value Decomposition (SVD)<br>
                            - Applications of dimensionality reduction<br>
                        </td>
                        <td><a href="cisc-435/readings/Principal Components Analysis.pdf">Andrew Ng: Principal
                                components analysis</a></td>
                        <td>Slides: <a href="cisc-435/lectures/22-svds.pdf">Dimensionality Reduction</a> <br> </td>
                        <td></td>
                        <td></td>
                    </tr>

                    <tr>
                        <th scope="row">Week 8: Midterm Exam</th>
                        <td colspan="5"> Midterm Review (10/17) + Midterm Exam (10/19) </td>
                    </tr>

                    <tr>
                        <th scope="row">Week 9: Support Vector Machines (SVM)</th>
                        <td>
                            - Geometric interpretation of SVM <br>
                            - Kernel trick and non-linear SVM <br>
                            - Hyperparameter tuning for SVM <br>
                            - Applications of SVM in real-world problems <br>

                        </td>
                        <td><a href="cisc-435/readings/Kernel Methods and SVM.pdf">Andrew Ng: Kernel Methods and SVM P. 11-15</a></td>
                        <td>Slides: <a href="cisc-435/lectures/06-svm.pdf">Support Vector Machines</a> <br> </td>
                        <td><a href="cisc-435/assignment/CISC_435_Assignment05.pdf">A05: PCA & SVM</a></td>
                        <td>A04: 10/19</td>
                    </tr>


                    <tr>
                        <th scope="row">Week 10: Neural Networks and Deep Learning</th>
                        <td>
                            - Introduction to neural networks <br>
                            - Feedforward neural networks<br>
                            - Backpropagation and gradient descent<br>
                            - Activation functions and loss functions <br>
                            - Introduction to deep learning frameworks (e.g., TensorFlow, Keras)<br>
                        </td>
                        <td><a href="cisc-435/readings/Neural Networks.pdf">Neural Networks</a></td>
                        <td>Slides: <a href="cisc-435/lectures/08-mlpercept.pdf">Neural Networks</a> <br> </td>
                        <td><a href="cisc-435/assignment/CISC_435_Assignment06.pdf">A06: Neural Networks</a></td>
                        <td>A05: 11/02</td>
                    </tr>

                    <tr>
                        <th scope="row">Week 11: Convolutional Neural Networks (CNNs)</th>
                        <td>
                            - Basics of CNNs <br>
                            - Image classification using CNNs <br>
                            - Transfer learning with pre-trained models <br>
                        </td>
                        <td></td>
                        <td>Slides: <a href="cisc-435/lectures/lec21_cnns_for_web.pdf">Convolutional Neural Networks</a>
                            <br> </td>
                            <td><a href="cisc-435/assignment/CISC_435_Assignment07.pdf">A07: CNN</a></td>
                            <td></td> 
                    </tr>

                    <tr>
                        <th scope="row">Week 12: Reinforcement Learning</th>
                        <td>
                            - Introduction to reinforcement learning<br>
                            - Markov Decision Processes (MDPs)<br>
                            - Q-learning and policy gradient methods<br>
                            - Applications of reinforcement learning<br>
                        </td>
                        <td></td>
                        <td>Slides: <a href="cisc-435/lectures/33-reinforce.pdf">Reinforcement Learning</a> <br> </td>
                        <td></td>
                        <td>A06: 11/16</td> 
                    </tr>
                    <tr>
                        <th scope="row">Week 13</th> 
                        <td colspan="5" style="text-align: center;">Thanksgiving Holiday</td>
                    </tr>

                    <tr>
                        <th scope="row">Week 14</th>
                        <td colspan="4">Final Exam Review(11/28) + Final Exam (11/30)</td> 
                        <td >A07: 11/30</td>
                    </tr>


                    <tr>
                        <th scope="row">Week 15: Final Project Presentations and Wrap-up</th>
                        <td>
                            - Students present their machine learning projects<br>
                            - Recap of key topics and discussion of future trends in machine learning <br>
                            - Final Exam Review
                        </td>
                        <td></td>
                        <td></td>
                        <td></td>
                        <td></td>
                    </tr>



                </tbody>
            </table>
        </section>
    </main>

    <footer class="mt-5">
        <div class="container">
           
            <div class="row mt-3">
                <div class="col-lg-12 text-center">
                    <p>This work is licensed under the <a href="https://opensource.org/licenses/MIT" target="_blank" rel="noopener noreferrer">MIT License</a>.</p>
                </div>
            </div>
        </div>
    </footer>
    

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.min.js"></script>
</body>

</html>